{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab1386d",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "#### CSCI 4502 Final Project\n",
    "#### Author: Ethan Meyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eef44fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0f367",
   "metadata": {},
   "source": [
    "# Importing Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "da79aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_joined_df = pd.read_csv(\"../data/Pre-Processed-Data/ModelData.csv\", index_col=0)\n",
    "target = full_joined_df['WinnerLabel']\n",
    "full_joined_df.head()\n",
    "\n",
    "targets = full_joined_df['WinnerLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1bd1917d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WinnerLabel</th>\n",
       "      <th>A_avg_Score</th>\n",
       "      <th>B_avg_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.800000</td>\n",
       "      <td>71.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.214286</td>\n",
       "      <td>67.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.517241</td>\n",
       "      <td>75.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.344828</td>\n",
       "      <td>79.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.482759</td>\n",
       "      <td>72.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  WinnerLabel  A_avg_Score  B_avg_Score\n",
       "0    2003     134          0.0    72.800000    71.206897\n",
       "1    2003     136          1.0    85.214286    67.793103\n",
       "2    2003     136          0.0    74.517241    75.965517\n",
       "3    2003     136          1.0    79.344828    79.242424\n",
       "4    2003     136          1.0    74.482759    72.400000"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_joined_df[['Season','DayNum','WinnerLabel','A_avg_Score','B_avg_Score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c54f38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_NumWins</th>\n",
       "      <th>A_avg_Score</th>\n",
       "      <th>A_avg_FGM</th>\n",
       "      <th>A_avg_FGA</th>\n",
       "      <th>A_avg_FGM3</th>\n",
       "      <th>A_avg_FGA3</th>\n",
       "      <th>A_avg_FTM</th>\n",
       "      <th>A_avg_FTA</th>\n",
       "      <th>A_avg_OR</th>\n",
       "      <th>A_avg_DR</th>\n",
       "      <th>...</th>\n",
       "      <th>B_avg_DefPtsPos</th>\n",
       "      <th>B_avg_NetPtsPos</th>\n",
       "      <th>B_avg_AstP</th>\n",
       "      <th>B_NumLosses</th>\n",
       "      <th>A_OrdinalRank</th>\n",
       "      <th>B_OrdinalRank</th>\n",
       "      <th>A_Seed</th>\n",
       "      <th>B_Seed</th>\n",
       "      <th>A_WinPct</th>\n",
       "      <th>B_WinPct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>72.800000</td>\n",
       "      <td>24.733333</td>\n",
       "      <td>55.266667</td>\n",
       "      <td>5.933333</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>28.066667</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.122992</td>\n",
       "      <td>-0.099691</td>\n",
       "      <td>0.188002</td>\n",
       "      <td>16.0</td>\n",
       "      <td>239.281250</td>\n",
       "      <td>240.343750</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>85.214286</td>\n",
       "      <td>30.321429</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>7.035714</td>\n",
       "      <td>20.071429</td>\n",
       "      <td>17.535714</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.178571</td>\n",
       "      <td>27.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>0.071297</td>\n",
       "      <td>0.217935</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>153.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>74.517241</td>\n",
       "      <td>26.275862</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.068966</td>\n",
       "      <td>14.965517</td>\n",
       "      <td>22.896552</td>\n",
       "      <td>14.068966</td>\n",
       "      <td>25.965517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999149</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.227179</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.705882</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>79.344828</td>\n",
       "      <td>26.620690</td>\n",
       "      <td>52.689655</td>\n",
       "      <td>6.827586</td>\n",
       "      <td>17.931034</td>\n",
       "      <td>19.275862</td>\n",
       "      <td>25.172414</td>\n",
       "      <td>10.586207</td>\n",
       "      <td>23.275862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939856</td>\n",
       "      <td>0.211275</td>\n",
       "      <td>0.243801</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.687500</td>\n",
       "      <td>20.735294</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>74.482759</td>\n",
       "      <td>27.344828</td>\n",
       "      <td>58.724138</td>\n",
       "      <td>6.413793</td>\n",
       "      <td>17.034483</td>\n",
       "      <td>13.379310</td>\n",
       "      <td>19.517241</td>\n",
       "      <td>11.241379</td>\n",
       "      <td>24.379310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023209</td>\n",
       "      <td>0.061666</td>\n",
       "      <td>0.218855</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.406250</td>\n",
       "      <td>50.312500</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A_NumWins  A_avg_Score  A_avg_FGM  A_avg_FGA  A_avg_FGM3  A_avg_FGA3  \\\n",
       "0       18.0    72.800000  24.733333  55.266667    5.933333   18.500000   \n",
       "1       25.0    85.214286  30.321429  65.714286    7.035714   20.071429   \n",
       "2       23.0    74.517241  26.275862  60.000000    7.000000   20.068966   \n",
       "3       23.0    79.344828  26.620690  52.689655    6.827586   17.931034   \n",
       "4       21.0    74.482759  27.344828  58.724138    6.413793   17.034483   \n",
       "\n",
       "   A_avg_FTM  A_avg_FTA   A_avg_OR   A_avg_DR  ...  B_avg_DefPtsPos  \\\n",
       "0  17.400000  28.066667  13.166667  24.800000  ...         1.122992   \n",
       "1  17.535714  25.000000  15.178571  27.642857  ...         0.967096   \n",
       "2  14.965517  22.896552  14.068966  25.965517  ...         0.999149   \n",
       "3  19.275862  25.172414  10.586207  23.275862  ...         0.939856   \n",
       "4  13.379310  19.517241  11.241379  24.379310  ...         1.023209   \n",
       "\n",
       "   B_avg_NetPtsPos  B_avg_AstP  B_NumLosses  A_OrdinalRank  B_OrdinalRank  \\\n",
       "0        -0.099691    0.188002         16.0     239.281250     240.343750   \n",
       "1         0.071297    0.217935         10.0       2.676471     153.125000   \n",
       "2         0.109800    0.227179         11.0      21.705882      36.000000   \n",
       "3         0.211275    0.243801          4.0      45.687500      20.735294   \n",
       "4         0.061666    0.218855         12.0      36.406250      50.312500   \n",
       "\n",
       "   A_Seed  B_Seed  A_WinPct  B_WinPct  \n",
       "0      16      16  0.600000  0.448276  \n",
       "1       1      16  0.892857  0.655172  \n",
       "2       7      10  0.793103  0.620690  \n",
       "3      11       6  0.793103  0.878788  \n",
       "4       8       9  0.724138  0.600000  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = ['Season','DayNum','WinnerLabel','ATeamID','AScore','BTeamID','BScore','NumOT']\n",
    "feature_df = full_joined_df.drop(columns=drop_cols,axis=1)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3ea925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumWins_diff</th>\n",
       "      <th>NumLosses_diff</th>\n",
       "      <th>WinPct_diff</th>\n",
       "      <th>PPG_diff</th>\n",
       "      <th>FGM_diff</th>\n",
       "      <th>FGA_diff</th>\n",
       "      <th>FGM3_diff</th>\n",
       "      <th>FGA3_diff</th>\n",
       "      <th>FTM_diff</th>\n",
       "      <th>FTA_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>FTR_diff</th>\n",
       "      <th>FTAR_diff</th>\n",
       "      <th>TSP_diff</th>\n",
       "      <th>Pos_diff</th>\n",
       "      <th>OffPtsPos_diff</th>\n",
       "      <th>DefPtsPos_diff</th>\n",
       "      <th>NetPtsPos_diff</th>\n",
       "      <th>AstP_diff</th>\n",
       "      <th>OrdinalRank_diff</th>\n",
       "      <th>Seed_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.151724</td>\n",
       "      <td>1.593103</td>\n",
       "      <td>0.354023</td>\n",
       "      <td>-1.526437</td>\n",
       "      <td>-0.549425</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.434483</td>\n",
       "      <td>7.135632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>0.152277</td>\n",
       "      <td>11761.181609</td>\n",
       "      <td>-0.279669</td>\n",
       "      <td>0.022172</td>\n",
       "      <td>-0.121670</td>\n",
       "      <td>0.143843</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>-1.062500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.237685</td>\n",
       "      <td>17.421182</td>\n",
       "      <td>5.493842</td>\n",
       "      <td>9.852217</td>\n",
       "      <td>1.759852</td>\n",
       "      <td>4.588670</td>\n",
       "      <td>4.673645</td>\n",
       "      <td>5.448276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037130</td>\n",
       "      <td>0.031691</td>\n",
       "      <td>107964.332512</td>\n",
       "      <td>10.731360</td>\n",
       "      <td>0.082223</td>\n",
       "      <td>-0.040683</td>\n",
       "      <td>0.122906</td>\n",
       "      <td>0.013217</td>\n",
       "      <td>-150.448529</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>-1.448276</td>\n",
       "      <td>-0.931034</td>\n",
       "      <td>3.103448</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.482759</td>\n",
       "      <td>-2.586207</td>\n",
       "      <td>-3.310345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053970</td>\n",
       "      <td>-0.071937</td>\n",
       "      <td>400.413793</td>\n",
       "      <td>1.073931</td>\n",
       "      <td>-0.040473</td>\n",
       "      <td>-0.053821</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.011253</td>\n",
       "      <td>-14.294118</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.085684</td>\n",
       "      <td>0.102403</td>\n",
       "      <td>-2.076280</td>\n",
       "      <td>-4.764890</td>\n",
       "      <td>-1.142111</td>\n",
       "      <td>-2.553814</td>\n",
       "      <td>5.397074</td>\n",
       "      <td>5.142111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124461</td>\n",
       "      <td>0.127689</td>\n",
       "      <td>-9497.456635</td>\n",
       "      <td>2.647394</td>\n",
       "      <td>-0.040235</td>\n",
       "      <td>0.086365</td>\n",
       "      <td>-0.126600</td>\n",
       "      <td>-0.025458</td>\n",
       "      <td>24.952206</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.124138</td>\n",
       "      <td>2.082759</td>\n",
       "      <td>3.011494</td>\n",
       "      <td>5.390805</td>\n",
       "      <td>-1.552874</td>\n",
       "      <td>-5.465517</td>\n",
       "      <td>-2.387356</td>\n",
       "      <td>-0.949425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057522</td>\n",
       "      <td>-0.039185</td>\n",
       "      <td>23262.262069</td>\n",
       "      <td>3.441223</td>\n",
       "      <td>-0.020934</td>\n",
       "      <td>-0.026102</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>-13.906250</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumWins_diff  NumLosses_diff  WinPct_diff   PPG_diff  FGM_diff  FGA_diff  \\\n",
       "0           5.0            -4.0     0.151724   1.593103  0.354023 -1.526437   \n",
       "1           6.0            -7.0     0.237685  17.421182  5.493842  9.852217   \n",
       "2           5.0            -5.0     0.172414  -1.448276 -0.931034  3.103448   \n",
       "3          -6.0             2.0    -0.085684   0.102403 -2.076280 -4.764890   \n",
       "4           3.0            -4.0     0.124138   2.082759  3.011494  5.390805   \n",
       "\n",
       "   FGM3_diff  FGA3_diff  FTM_diff  FTA_diff  ...  FTR_diff  FTAR_diff  \\\n",
       "0  -0.549425   0.500000  1.434483  7.135632  ...  0.042472   0.152277   \n",
       "1   1.759852   4.588670  4.673645  5.448276  ...  0.037130   0.031691   \n",
       "2   3.000000   7.482759 -2.586207 -3.310345  ... -0.053970  -0.071937   \n",
       "3  -1.142111  -2.553814  5.397074  5.142111  ...  0.124461   0.127689   \n",
       "4  -1.552874  -5.465517 -2.387356 -0.949425  ... -0.057522  -0.039185   \n",
       "\n",
       "        TSP_diff   Pos_diff  OffPtsPos_diff  DefPtsPos_diff  NetPtsPos_diff  \\\n",
       "0   11761.181609  -0.279669        0.022172       -0.121670        0.143843   \n",
       "1  107964.332512  10.731360        0.082223       -0.040683        0.122906   \n",
       "2     400.413793   1.073931       -0.040473       -0.053821        0.013348   \n",
       "3   -9497.456635   2.647394       -0.040235        0.086365       -0.126600   \n",
       "4   23262.262069   3.441223       -0.020934       -0.026102        0.005169   \n",
       "\n",
       "   AstP_diff  OrdinalRank_diff  Seed_diff  \n",
       "0   0.014735         -1.062500          0  \n",
       "1   0.013217       -150.448529        -15  \n",
       "2   0.011253        -14.294118         -3  \n",
       "3  -0.025458         24.952206          5  \n",
       "4   0.008755        -13.906250         -1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Difference in Features Data Frame\n",
    "feature_difference_df = pd.DataFrame()\n",
    "feature_difference_df['NumWins_diff'] = feature_df['A_NumWins'] - feature_df['B_NumWins']\n",
    "feature_difference_df['NumLosses_diff'] = feature_df['A_NumLosses'] - feature_df['B_NumLosses']\n",
    "feature_difference_df['WinPct_diff'] = feature_df['A_WinPct'] - feature_df['B_WinPct']\n",
    "feature_difference_df['PPG_diff'] = feature_df['A_avg_Score'] - feature_df['B_avg_Score']\n",
    "feature_difference_df['FGM_diff'] = feature_df['A_avg_FGM'] - feature_df['B_avg_FGM']\n",
    "feature_difference_df['FGA_diff'] = feature_df['A_avg_FGA'] - feature_df['B_avg_FGA']\n",
    "feature_difference_df['FGM3_diff'] = feature_df['A_avg_FGM3'] - feature_df['B_avg_FGM3']\n",
    "feature_difference_df['FGA3_diff'] = feature_df['A_avg_FGA3'] - feature_df['B_avg_FGA3']\n",
    "feature_difference_df['FTM_diff'] = feature_df['A_avg_FTM'] - feature_df['B_avg_FTM']\n",
    "feature_difference_df['FTA_diff'] = feature_df['A_avg_FTA'] - feature_df['B_avg_FTA']\n",
    "feature_difference_df['OR_diff'] = feature_df['A_avg_OR'] - feature_df['B_avg_OR']\n",
    "feature_difference_df['DR_diff'] = feature_df['A_avg_DR'] - feature_df['B_avg_DR']\n",
    "feature_difference_df['Ast_diff'] = feature_df['A_avg_Ast'] - feature_df['B_avg_Ast']\n",
    "feature_difference_df['TO_diff'] = feature_df['A_avg_TO'] - feature_df['B_avg_TO']\n",
    "feature_difference_df['Stl_diff'] = feature_df['A_avg_Stl'] - feature_df['B_avg_Stl']\n",
    "feature_difference_df['Blk_diff'] = feature_df['A_avg_Blk'] - feature_df['B_avg_Blk']\n",
    "feature_difference_df['PF_diff'] = feature_df['A_avg_PF'] - feature_df['B_avg_PF']\n",
    "feature_difference_df['FGPct_diff'] = feature_df['A_avg_FGPct'] - feature_df['B_avg_FGPct']\n",
    "feature_difference_df['FG3Pct_diff'] = feature_df['A_avg_FG3Pct'] - feature_df['B_avg_FG3Pct']\n",
    "feature_difference_df['EFGP_diff'] = feature_df['A_avg_EFGP'] - feature_df['B_avg_EFGP']\n",
    "feature_difference_df['TP_diff'] = feature_df['A_avg_TP'] - feature_df['B_avg_TP']\n",
    "feature_difference_df['ORP_diff'] = feature_df['A_avg_ORP'] - feature_df['B_avg_ORP']\n",
    "feature_difference_df['DRP_diff'] = feature_df['A_avg_DRP'] - feature_df['B_avg_DRP']\n",
    "feature_difference_df['RP_diff'] = feature_df['A_avg_RP'] - feature_df['B_avg_RP']\n",
    "feature_difference_df['FTR_diff'] = feature_df['A_avg_FTR'] - feature_df['B_avg_FTR']\n",
    "feature_difference_df['FTAR_diff'] = feature_df['A_avg_FTAR'] - feature_df['B_avg_FTAR']\n",
    "feature_difference_df['TSP_diff'] = feature_df['A_avg_TSP'] - feature_df['B_avg_TSP']\n",
    "feature_difference_df['Pos_diff'] = feature_df['A_avg_Pos'] - feature_df['B_avg_Pos']\n",
    "feature_difference_df['OffPtsPos_diff'] = feature_df['A_avg_OffPtsPos'] - feature_df['B_avg_OffPtsPos']\n",
    "feature_difference_df['DefPtsPos_diff'] = feature_df['A_avg_DefPtsPos'] - feature_df['B_avg_DefPtsPos']\n",
    "feature_difference_df['NetPtsPos_diff'] = feature_df['A_avg_NetPtsPos'] - feature_df['B_avg_NetPtsPos']\n",
    "feature_difference_df['AstP_diff'] = feature_df['A_avg_AstP'] - feature_df['B_avg_AstP']\n",
    "feature_difference_df['OrdinalRank_diff'] = feature_df['A_OrdinalRank'] - feature_df['B_OrdinalRank']\n",
    "feature_difference_df['Seed_diff'] = feature_df['A_Seed'] - feature_df['B_Seed']\n",
    "\n",
    "\n",
    "feature_difference_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af722656",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f63c0",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f41c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR LogLoss Tuned Hyperparameters : {'logreg__C': 0.1, 'logreg__penalty': 'l2', 'logreg__solver': 'liblinear'}\n",
      "LogLoss : 0.5504654850239427\n",
      "LR Accuracy Tuned Hyperparameters : {'logreg__C': 1.0, 'logreg__penalty': 'l1', 'logreg__solver': 'liblinear'}\n",
      "Accuracy : 0.7072649572649572\n"
     ]
    }
   ],
   "source": [
    "LR_Pipeline = Pipeline([\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "LR_Parameters = {\n",
    "    'logreg__penalty' : ['l1','l2'], \n",
    "    'logreg__C'       : np.logspace(-3,3,7),\n",
    "    'logreg__solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=10,test_size=.2)\n",
    "\n",
    "\n",
    "# LogLoss Scoring\n",
    "\n",
    "LR_logloss_model = GridSearchCV(LR_Pipeline,                    \n",
    "                   param_grid = LR_Parameters,   \n",
    "                   scoring='neg_log_loss',        \n",
    "                   cv=shuffle_split)                     \n",
    "\n",
    "LR_logloss_model.fit(feature_difference_df,target)\n",
    "\n",
    "print(\"LR LogLoss Tuned Hyperparameters :\", LR_logloss_model.best_params_)\n",
    "print(\"LogLoss :\",-LR_logloss_model.best_score_)\n",
    "\n",
    "best_LR_logloss_model = LogisticRegression(C = LR_logloss_model.best_params_['logreg__C'], \n",
    "                            penalty = LR_logloss_model.best_params_['logreg__penalty'], \n",
    "                            solver = LR_logloss_model.best_params_['logreg__solver'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy Scoring\n",
    "\n",
    "LR_acc_model = GridSearchCV(LR_Pipeline,                    \n",
    "                   param_grid = LR_Parameters,   \n",
    "                   scoring='accuracy',        \n",
    "                   cv=shuffle_split)                     \n",
    "\n",
    "LR_acc_model.fit(feature_difference_df,target)\n",
    "\n",
    "print(\"LR Accuracy Tuned Hyperparameters :\", LR_acc_model.best_params_)\n",
    "print(\"Accuracy :\",LR_acc_model.best_score_)\n",
    "\n",
    "best_LR_acc_model = LogisticRegression(C = LR_acc_model.best_params_['logreg__C'], \n",
    "                            penalty = LR_acc_model.best_params_['logreg__penalty'], \n",
    "                            solver = LR_acc_model.best_params_['logreg__solver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c17ea",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "dff094d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM LogLoss Tuned Hyperparameters : {'svm__C': 100, 'svm__gamma': 0.0001, 'svm__kernel': 'rbf'}\n",
      "LogLoss : 0.5301127628819547\n",
      "SVM Accuracy Tuned Hyperparameters : {'svm__C': 100, 'svm__gamma': 0.0001, 'svm__kernel': 'rbf'}\n",
      "Accuracy : 0.7230769230769231\n"
     ]
    }
   ],
   "source": [
    "SVM_Pipeline = Pipeline([\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "SVM_Parameters = {\n",
    "    'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'svm__kernel': ['sigmoid','rbf'],\n",
    "    'svm__C': [0.1, 1, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=10,test_size=.2)\n",
    "\n",
    "# LogLoss Scoring\n",
    "\n",
    "SVM_logloss_model = GridSearchCV(SVM_Pipeline,                    \n",
    "                   param_grid = SVM_Parameters,   \n",
    "                   scoring='neg_log_loss',        \n",
    "                   cv=shuffle_split)                     \n",
    "\n",
    "SVM_logloss_model.fit(feature_difference_df,target)\n",
    "\n",
    "print(\"SVM LogLoss Tuned Hyperparameters :\", SVM_logloss_model.best_params_)\n",
    "print(\"LogLoss :\",-SVM_logloss_model.best_score_)\n",
    "\n",
    "best_SVM_logloss_model = SVC(probability = True,\n",
    "                             C = SVM_logloss_model.best_params_['svm__C'], \n",
    "                            gamma = SVM_logloss_model.best_params_['svm__gamma'], \n",
    "                            kernel = SVM_logloss_model.best_params_['svm__kernel'])\n",
    "\n",
    "# Accuracy Scoring\n",
    "SVM_acc_model = GridSearchCV(SVM_Pipeline,                    \n",
    "                   param_grid = SVM_Parameters,   \n",
    "                   scoring='accuracy',        \n",
    "                   cv=shuffle_split)                     \n",
    "\n",
    "SVM_acc_model.fit(feature_difference_df,target)\n",
    "\n",
    "print(\"SVM Accuracy Tuned Hyperparameters :\", SVM_acc_model.best_params_)\n",
    "print(\"Accuracy :\",SVM_acc_model.best_score_)\n",
    "\n",
    "best_SVM_acc_model = SVC(probability = True,C = SVM_acc_model.best_params_['svm__C'], \n",
    "                            gamma = SVM_acc_model.best_params_['svm__gamma'], \n",
    "                            kernel = SVM_acc_model.best_params_['svm__kernel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b53195",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6152dda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN LogLoss Tuned Hyperparameters : {'knn__n_neighbors': 19}\n",
      "LogLoss : 0.6066754154677698\n",
      "KNN Accuracy Tuned Hyperparameters : {'knn__n_neighbors': 18}\n",
      "Accuracy : 0.6786324786324787\n"
     ]
    }
   ],
   "source": [
    "KNN_Pipeline = Pipeline([\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "KNN_Parameters = {\n",
    "    'knn__n_neighbors': range(1,20), \n",
    "}\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=10,test_size=.2)\n",
    "\n",
    "# LogLoss Scoring\n",
    "\n",
    "KNN_logloss_model = GridSearchCV(KNN_Pipeline,                    \n",
    "                   param_grid = KNN_Parameters,   \n",
    "                   scoring='neg_log_loss',        \n",
    "                   cv=shuffle_split)                     \n",
    "\n",
    "KNN_logloss_model.fit(feature_difference_df,target)\n",
    "\n",
    "print(\"KNN LogLoss Tuned Hyperparameters :\", KNN_logloss_model.best_params_)\n",
    "print(\"LogLoss :\",-KNN_logloss_model.best_score_)\n",
    "\n",
    "best_KNN_logloss_model = KNeighborsClassifier(n_neighbors=KNN_logloss_model.best_params_['knn__n_neighbors'])\n",
    "\n",
    "# Accuracy Scoring\n",
    "KNN_acc_model = GridSearchCV(KNN_Pipeline,                    \n",
    "                   param_grid = KNN_Parameters,   \n",
    "                   scoring='accuracy',        \n",
    "                   cv=shuffle_split)                     \n",
    "\n",
    "KNN_acc_model.fit(feature_difference_df,target)\n",
    "\n",
    "print(\"KNN Accuracy Tuned Hyperparameters :\", KNN_acc_model.best_params_)\n",
    "print(\"Accuracy :\",KNN_acc_model.best_score_)\n",
    "\n",
    "best_KNN_acc_model = KNeighborsClassifier(n_neighbors=KNN_acc_model.best_params_['knn__n_neighbors'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fc8bf",
   "metadata": {},
   "source": [
    "# Uniform Betting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d524bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful Functions\n",
    "\n",
    "def get_bet_on_team(row):\n",
    "    if row['Prediction'] == 1:\n",
    "        return row['ATeamID']\n",
    "    else:\n",
    "        return row['BTeamID']\n",
    "    \n",
    "def calc_net_payout(moneyline, amount_bet = 1, correct=True):\n",
    "    if correct:\n",
    "        if moneyline < 0:\n",
    "            return -amount_bet*(100/moneyline)\n",
    "        else:\n",
    "            return amount_bet*(moneyline/100)\n",
    "    else:\n",
    "        return -amount_bet\n",
    "    \n",
    "def calc_implied_p(moneyline):\n",
    "    if moneyline < 0:\n",
    "        return (-1*(moneyline)) / (-1*(moneyline) + 100)\n",
    "    else:\n",
    "        return 100 / (moneyline + 100)\n",
    "    \n",
    "def test_model(model, features, targets):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, targets, test_size=0.2)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    test_bet_output = full_joined_df.iloc[y_test.index][['Season', 'DayNum', 'ATeamID', 'BTeamID','WinnerLabel']]\n",
    "    test_bet_output['Prediction'] = y_pred\n",
    "    test_bet_output['Correct?'] = test_bet_output['WinnerLabel'] == test_bet_output['Prediction']\n",
    "    test_bet_output['BetOnTeamID'] = test_bet_output.apply(get_bet_on_team, axis=1)\n",
    "    \n",
    "    test_bet_full_df = test_bet_output.merge(moneyline_df, how=\"left\",  \n",
    "                                         left_on=[\"Season\",\"DayNum\",\"BetOnTeamID\"], right_on=[\"Season\",\"DayNum\",\"TeamID\"])[['Season','BetOnTeamID','Correct?','Moneyline']]\n",
    "\n",
    "    test_bet_full_df = test_bet_full_df.dropna()\n",
    "    \n",
    "    initial_investment = len(test_bet_full_df.index)\n",
    "    running_balanace = initial_investment\n",
    "    \n",
    "    for idx, row in test_bet_full_df.iterrows():\n",
    "        if row[\"Correct?\"]:\n",
    "            running_balanace += calc_net_payout(row[\"Moneyline\"])\n",
    "        else:\n",
    "            running_balanace -= 1\n",
    "\n",
    "    ROI = (running_balanace - initial_investment)/initial_investment\n",
    "    accuracy = sum(y_pred == y_test)/len(y_pred)\n",
    "    return ROI, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619ea9a",
   "metadata": {},
   "source": [
    "# Enhanced Betting Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dfb3567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data to be compatable with already constructed models\n",
    "scaler = preprocessing.StandardScaler().fit(feature_difference_df)\n",
    "scaled_feature_diff_df = scaler.transform(feature_difference_df)\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_feature_diff_df, targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba21697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bet_Team_from_edge(edge_a, edge_b):\n",
    "    if edge_a > 0:\n",
    "        return 1\n",
    "    elif edge_b > 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_edge_from_bet_Team(bet_on_team, edge_a, edge_b):\n",
    "    if pd.isna(bet_on_team):\n",
    "        return None\n",
    "    elif bet_on_team == 1:\n",
    "        return edge_a\n",
    "    else:\n",
    "        return edge_b\n",
    "    \n",
    "def get_moneyline_from_bet_Team(bet_on_team, moneyline_a, moneyline_b):\n",
    "    if pd.isna(bet_on_team):\n",
    "        return None\n",
    "    elif bet_on_team == 1:\n",
    "        return moneyline_a\n",
    "    else:\n",
    "        return moneyline_b    \n",
    "    \n",
    "def check_bet_correct(bet_on_team, winner_label):\n",
    "    if pd.isna(bet_on_team):\n",
    "        return None\n",
    "    else:\n",
    "        return bet_on_team == winner_label\n",
    "\n",
    "    \n",
    "\n",
    "def test_enhanced_betting(model, feature_df, targets):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feature_df, targets, test_size=0.2)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_prob = model.predict_proba(x_test)\n",
    "\n",
    "    B_prob = [array[0] for array in y_prob]\n",
    "    A_prob = [array[1] for array in y_prob]\n",
    "\n",
    "    test_bet_output = full_joined_df.iloc[y_test.index][['Season', 'DayNum', 'ATeamID', 'BTeamID','WinnerLabel']]\n",
    "    \n",
    "    test_bet_output['P(A)'] = A_prob\n",
    "    test_bet_output['P(B)'] = B_prob\n",
    "\n",
    "    test_bet_full_df = test_bet_output.merge(moneyline_df, how=\"left\",\n",
    "                          left_on=[\"Season\",\"DayNum\",\"ATeamID\"], \n",
    "                          right_on=[\"Season\",\"DayNum\",\"TeamID\"]).rename(columns={\"Moneyline\":\"A_Moneyline\"})\n",
    "\n",
    "    test_bet_full_df = test_bet_full_df.merge(moneyline_df, how=\"left\",\n",
    "                          left_on=[\"Season\",\"DayNum\",\"BTeamID\"], \n",
    "                          right_on=[\"Season\",\"DayNum\",\"TeamID\"]).rename(columns={\"Moneyline\":\"B_Moneyline\"})\n",
    "\n",
    "\n",
    "    test_bet_full_df['Imp. P(A)'] = test_bet_full_df['A_Moneyline'].apply(calc_implied_p)\n",
    "    test_bet_full_df['Imp. P(B)'] = test_bet_full_df['B_Moneyline'].apply(calc_implied_p)\n",
    "\n",
    "    test_bet_full_df['Total Imp. P'] = test_bet_full_df['Imp. P(A)'] + test_bet_full_df['Imp. P(B)']\n",
    "\n",
    "    test_bet_full_df['Edge(A)'] = test_bet_full_df['P(A)'] - test_bet_full_df['Imp. P(A)']\n",
    "    test_bet_full_df['Edge(B)'] = test_bet_full_df['P(B)'] - test_bet_full_df['Imp. P(B)']\n",
    "\n",
    "    test_bet_full_df['BetOnTeam'] = test_bet_full_df.apply(lambda row: get_bet_Team_from_edge(row['Edge(A)'],row['Edge(B)']), axis=1)\n",
    "    test_bet_full_df['BetEdge'] = test_bet_full_df.apply(lambda row: get_edge_from_bet_Team(row['BetOnTeam'],row['Edge(A)'],row['Edge(B)']), axis=1)\n",
    "    test_bet_full_df['BetMoneyline'] = test_bet_full_df.apply(lambda row: get_moneyline_from_bet_Team(row['BetOnTeam'],row['A_Moneyline'],row['B_Moneyline']), axis=1)\n",
    "    test_bet_full_df['Correct?'] = test_bet_full_df.apply(lambda row: check_bet_correct(row['BetOnTeam'],row['WinnerLabel']), axis=1)    \n",
    "\n",
    "    return test_bet_full_df\n",
    "    \n",
    "    test_compact_bet_full_df = test_bet_full_df[['BetOnTeam','BetMoneyline','Correct?','BetEdge']]\n",
    "\n",
    "    initial_investment = 100\n",
    "    test_compact_bet_full_df['BetAmount'] = initial_investment* (test_compact_bet_full_df['BetEdge'] / test_compact_bet_full_df['BetEdge'].sum(skipna=True))\n",
    "    test_compact_bet_full_df['NetPayout'] = test_compact_bet_full_df.apply(lambda row: calc_net_payout(row['BetMoneyline'], row['BetAmount'], row['Correct?']), axis=1)\n",
    "\n",
    "    accuracy = test_compact_bet_full_df['Correct?'].sum(skipna=True) / test_compact_bet_full_df['Correct?'].count()\n",
    "    ROI = test_compact_bet_full_df['NetPayout'].sum(skipna=True) / initial_investment\n",
    "\n",
    "    return ROI, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1648286",
   "metadata": {},
   "source": [
    "# Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c150c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>Moneyline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1263</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1350</td>\n",
       "      <td>-240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1404</td>\n",
       "      <td>13000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1272</td>\n",
       "      <td>-39000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1205</td>\n",
       "      <td>-160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  DayNum  TeamID  Moneyline\n",
       "0    2008       0    1263      200.0\n",
       "1    2008       0    1350     -240.0\n",
       "2    2008       0    1404    13000.0\n",
       "3    2008       0    1272   -39000.0\n",
       "4    2008       1    1205     -160.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading betting data\n",
    "moneyline_df = pd.read_csv(\"../data/Pre-Processed-Data/CleanedMoneylineData.csv\",index_col=0)\n",
    "moneyline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "c1f2ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "num_trials = 500\n",
    "\n",
    "# Trackers for basic betting strategy\n",
    "LR_logloss_ROI_tracker_basic = np.empty(num_trials)\n",
    "LR_logloss_accuracy_tracker_basic = np.empty(num_trials)\n",
    "LR_acc_ROI_tracker_basic = np.empty(num_trials)\n",
    "LR_acc_accuracy_tracker_basic = np.empty(num_trials)\n",
    "\n",
    "# Trackers for enhanced betting strategy\n",
    "LR_logloss_ROI_tracker_enh = np.empty(num_trials)\n",
    "LR_logloss_accuracy_tracker_enh = np.empty(num_trials)\n",
    "LR_acc_ROI_tracker_enh = np.empty(num_trials)\n",
    "LR_acc_accuracy_tracker_enh = np.empty(num_trials)\n",
    "\n",
    "\n",
    "for idx in range(num_trials):\n",
    "    ROI, acc = test_model(best_LR_logloss_model,scaled_feature_diff_df, targets)\n",
    "    LR_logloss_ROI_tracker_basic[idx] = ROI\n",
    "    LR_logloss_accuracy_tracker_basic[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_model(best_LR_acc_model,scaled_feature_diff_df, targets)\n",
    "    LR_acc_ROI_tracker_basic[idx] = ROI\n",
    "    LR_acc_accuracy_tracker_basic[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_enhanced_betting(best_LR_logloss_model,scaled_feature_diff_df, targets)\n",
    "    LR_logloss_ROI_tracker_enh[idx] = ROI\n",
    "    LR_logloss_accuracy_tracker_enh[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_enhanced_betting(best_LR_acc_model,scaled_feature_diff_df, targets)\n",
    "    LR_acc_ROI_tracker_enh[idx] = ROI\n",
    "    LR_acc_accuracy_tracker_enh[idx] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "0647b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "num_trials = 500\n",
    "\n",
    "# Trackers for basic betting strategy\n",
    "SVM_logloss_ROI_tracker_basic = np.empty(num_trials)\n",
    "SVM_logloss_accuracy_tracker_basic = np.empty(num_trials)\n",
    "SVM_acc_ROI_tracker_basic = np.empty(num_trials)\n",
    "SVM_acc_accuracy_tracker_basic = np.empty(num_trials)\n",
    "\n",
    "# Trackers for enhanced betting strategy\n",
    "SVM_logloss_ROI_tracker_enh = np.empty(num_trials)\n",
    "SVM_logloss_accuracy_tracker_enh = np.empty(num_trials)\n",
    "SVM_acc_ROI_tracker_enh = np.empty(num_trials)\n",
    "SVM_acc_accuracy_tracker_enh = np.empty(num_trials)\n",
    "\n",
    "\n",
    "for idx in range(num_trials):\n",
    "    ROI, acc = test_model(best_SVM_logloss_model,scaled_feature_diff_df, targets)\n",
    "    SVM_logloss_ROI_tracker_basic[idx] = ROI\n",
    "    SVM_logloss_accuracy_tracker_basic[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_model(best_SVM_acc_model,scaled_feature_diff_df, targets)\n",
    "    SVM_acc_ROI_tracker_basic[idx] = ROI\n",
    "    SVM_acc_accuracy_tracker_basic[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_enhanced_betting(best_SVM_logloss_model,scaled_feature_diff_df, targets)\n",
    "    SVM_logloss_ROI_tracker_enh[idx] = ROI\n",
    "    SVM_logloss_accuracy_tracker_enh[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_enhanced_betting(best_SVM_acc_model,scaled_feature_diff_df, targets)\n",
    "    SVM_acc_ROI_tracker_enh[idx] = ROI\n",
    "    SVM_acc_accuracy_tracker_enh[idx] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "235bf9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "num_trials = 500\n",
    "\n",
    "# Trackers for basic betting strategy\n",
    "KNN_logloss_ROI_tracker_basic = np.empty(num_trials)\n",
    "KNN_logloss_accuracy_tracker_basic = np.empty(num_trials)\n",
    "KNN_acc_ROI_tracker_basic = np.empty(num_trials)\n",
    "KNN_acc_accuracy_tracker_basic = np.empty(num_trials)\n",
    "\n",
    "# Trackers for enhanced betting strategy\n",
    "KNN_logloss_ROI_tracker_enh = np.empty(num_trials)\n",
    "KNN_logloss_accuracy_tracker_enh = np.empty(num_trials)\n",
    "KNN_acc_ROI_tracker_enh = np.empty(num_trials)\n",
    "KNN_acc_accuracy_tracker_enh = np.empty(num_trials)\n",
    "\n",
    "\n",
    "for idx in range(num_trials):\n",
    "    ROI, acc = test_model(best_KNN_logloss_model,scaled_feature_diff_df, targets)\n",
    "    KNN_logloss_ROI_tracker_basic[idx] = ROI\n",
    "    KNN_logloss_accuracy_tracker_basic[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_model(best_KNN_acc_model,scaled_feature_diff_df, targets)\n",
    "    KNN_acc_ROI_tracker_basic[idx] = ROI\n",
    "    KNN_acc_accuracy_tracker_basic[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_enhanced_betting(best_KNN_logloss_model,scaled_feature_diff_df, targets)\n",
    "    KNN_logloss_ROI_tracker_enh[idx] = ROI\n",
    "    KNN_logloss_accuracy_tracker_enh[idx] = acc\n",
    "    \n",
    "    ROI, acc = test_enhanced_betting(best_KNN_acc_model,scaled_feature_diff_df, targets)\n",
    "    KNN_acc_ROI_tracker_enh[idx] = ROI\n",
    "    KNN_acc_accuracy_tracker_enh[idx] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "81dd6ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR logloss Accuracy Basic</th>\n",
       "      <th>LR logloss ROI Basic</th>\n",
       "      <th>LR logloss Accuracy Enhanced</th>\n",
       "      <th>LR logloss ROI Enhanced</th>\n",
       "      <th>LR acc Accuracy Basic</th>\n",
       "      <th>LR acc ROI Basic</th>\n",
       "      <th>LR acc Accuracy Enhanced</th>\n",
       "      <th>LR acc ROI Enhanced</th>\n",
       "      <th>SVM logloss Accuracy Basic</th>\n",
       "      <th>SVM logloss ROI Basic</th>\n",
       "      <th>...</th>\n",
       "      <th>SVM acc Accuracy Enhanced</th>\n",
       "      <th>SVM acc ROI Enhanced</th>\n",
       "      <th>KNN logloss Accuracy Basic</th>\n",
       "      <th>KNN logloss ROI Basic</th>\n",
       "      <th>KNN logloss Accuracy Enhanced</th>\n",
       "      <th>KNN logloss ROI Enhanced</th>\n",
       "      <th>KNN acc Accuracy Basic</th>\n",
       "      <th>KNN acc ROI Basic</th>\n",
       "      <th>KNN acc Accuracy Enhanced</th>\n",
       "      <th>KNN acc ROI Enhanced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.137225</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>-0.006052</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>0.222422</td>\n",
       "      <td>0.726496</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>-0.166044</td>\n",
       "      <td>0.675214</td>\n",
       "      <td>-0.015598</td>\n",
       "      <td>0.343949</td>\n",
       "      <td>-0.060441</td>\n",
       "      <td>0.696581</td>\n",
       "      <td>0.057852</td>\n",
       "      <td>0.411392</td>\n",
       "      <td>0.215299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.683761</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.068812</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.102424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.020974</td>\n",
       "      <td>0.658120</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>-0.050501</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>-0.072702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.679487</td>\n",
       "      <td>-0.052164</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.080366</td>\n",
       "      <td>0.696581</td>\n",
       "      <td>-0.010790</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.052323</td>\n",
       "      <td>0.683761</td>\n",
       "      <td>-0.017402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469565</td>\n",
       "      <td>0.161442</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>-0.109780</td>\n",
       "      <td>0.386503</td>\n",
       "      <td>0.479738</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>-0.055491</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>-0.055430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>-0.259428</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.058449</td>\n",
       "      <td>0.421769</td>\n",
       "      <td>-0.209736</td>\n",
       "      <td>0.713675</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404110</td>\n",
       "      <td>-0.109679</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>-0.121181</td>\n",
       "      <td>0.328947</td>\n",
       "      <td>-0.184337</td>\n",
       "      <td>0.670940</td>\n",
       "      <td>-0.048690</td>\n",
       "      <td>0.329268</td>\n",
       "      <td>-0.302344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.041377</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.118001</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>-0.026183</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.048426</td>\n",
       "      <td>0.619658</td>\n",
       "      <td>-0.126970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.226024</td>\n",
       "      <td>0.645299</td>\n",
       "      <td>-0.033797</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.216952</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>-0.065050</td>\n",
       "      <td>0.401316</td>\n",
       "      <td>0.176808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LR logloss Accuracy Basic  LR logloss ROI Basic  \\\n",
       "0                   0.709402              0.001483   \n",
       "1                   0.683761              0.028666   \n",
       "2                   0.679487             -0.052164   \n",
       "3                   0.722222              0.008103   \n",
       "4                   0.709402              0.041377   \n",
       "\n",
       "   LR logloss Accuracy Enhanced  LR logloss ROI Enhanced  \\\n",
       "0                      0.522388                 0.137225   \n",
       "1                      0.441176                 0.068812   \n",
       "2                      0.537313                 0.080366   \n",
       "3                      0.460526                -0.259428   \n",
       "4                      0.456522                 0.118001   \n",
       "\n",
       "   LR acc Accuracy Basic  LR acc ROI Basic  LR acc Accuracy Enhanced  \\\n",
       "0               0.717949         -0.006052                  0.624060   \n",
       "1               0.743590          0.014586                  0.476190   \n",
       "2               0.696581         -0.010790                  0.544118   \n",
       "3               0.692308          0.058449                  0.421769   \n",
       "4               0.705128         -0.026183                  0.559441   \n",
       "\n",
       "   LR acc ROI Enhanced  SVM logloss Accuracy Basic  SVM logloss ROI Basic  \\\n",
       "0             0.222422                    0.726496               0.004700   \n",
       "1             0.018558                    0.764957               0.102424   \n",
       "2             0.052323                    0.683761              -0.017402   \n",
       "3            -0.209736                    0.713675               0.011192   \n",
       "4             0.048426                    0.619658              -0.126970   \n",
       "\n",
       "   ...  SVM acc Accuracy Enhanced  SVM acc ROI Enhanced  \\\n",
       "0  ...                   0.347826             -0.166044   \n",
       "1  ...                   0.500000              0.020974   \n",
       "2  ...                   0.469565              0.161442   \n",
       "3  ...                   0.404110             -0.109679   \n",
       "4  ...                   0.477273              0.226024   \n",
       "\n",
       "   KNN logloss Accuracy Basic  KNN logloss ROI Basic  \\\n",
       "0                    0.675214              -0.015598   \n",
       "1                    0.658120               0.010402   \n",
       "2                    0.623932              -0.109780   \n",
       "3                    0.628205              -0.121181   \n",
       "4                    0.645299              -0.033797   \n",
       "\n",
       "   KNN logloss Accuracy Enhanced  KNN logloss ROI Enhanced  \\\n",
       "0                       0.343949                 -0.060441   \n",
       "1                       0.406667                 -0.050501   \n",
       "2                       0.386503                  0.479738   \n",
       "3                       0.328947                 -0.184337   \n",
       "4                       0.377358                  0.216952   \n",
       "\n",
       "   KNN acc Accuracy Basic  KNN acc ROI Basic  KNN acc Accuracy Enhanced  \\\n",
       "0                0.696581           0.057852                   0.411392   \n",
       "1                0.653846          -0.000453                   0.392405   \n",
       "2                0.653846          -0.055491                   0.320988   \n",
       "3                0.670940          -0.048690                   0.329268   \n",
       "4                0.653846          -0.065050                   0.401316   \n",
       "\n",
       "   KNN acc ROI Enhanced  \n",
       "0              0.215299  \n",
       "1             -0.072702  \n",
       "2             -0.055430  \n",
       "3             -0.302344  \n",
       "4              0.176808  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\"LR logloss Accuracy Basic\":LR_logloss_accuracy_tracker_basic,\n",
    "                          \"LR logloss ROI Basic\":LR_logloss_ROI_tracker_basic,\n",
    "                          \"LR logloss Accuracy Enhanced\":LR_logloss_accuracy_tracker_enh,\n",
    "                          \"LR logloss ROI Enhanced\":LR_logloss_ROI_tracker_enh,\n",
    "                          \"LR acc Accuracy Basic\":LR_acc_accuracy_tracker_basic,\n",
    "                          \"LR acc ROI Basic\":LR_acc_ROI_tracker_basic,\n",
    "                          \"LR acc Accuracy Enhanced\":LR_acc_accuracy_tracker_enh,\n",
    "                          \"LR acc ROI Enhanced\":LR_acc_ROI_tracker_enh,\n",
    "                           \n",
    "                          \"SVM logloss Accuracy Basic\":SVM_logloss_accuracy_tracker_basic,\n",
    "                          \"SVM logloss ROI Basic\":SVM_logloss_ROI_tracker_basic,\n",
    "                          \"SVM logloss Accuracy Enhanced\":SVM_logloss_accuracy_tracker_enh,\n",
    "                          \"SVM logloss ROI Enhanced\":SVM_logloss_ROI_tracker_enh,\n",
    "                          \"SVM acc Accuracy Basic\":SVM_acc_accuracy_tracker_basic,\n",
    "                          \"SVM acc ROI Basic\":SVM_acc_ROI_tracker_basic,\n",
    "                          \"SVM acc Accuracy Enhanced\":SVM_acc_accuracy_tracker_enh,\n",
    "                          \"SVM acc ROI Enhanced\":SVM_acc_ROI_tracker_enh,\n",
    "                           \n",
    "                          \"KNN logloss Accuracy Basic\":KNN_logloss_accuracy_tracker_basic,\n",
    "                          \"KNN logloss ROI Basic\":KNN_logloss_ROI_tracker_basic,\n",
    "                          \"KNN logloss Accuracy Enhanced\":KNN_logloss_accuracy_tracker_enh,\n",
    "                          \"KNN logloss ROI Enhanced\":KNN_logloss_ROI_tracker_enh,\n",
    "                          \"KNN acc Accuracy Basic\":KNN_acc_accuracy_tracker_basic,\n",
    "                          \"KNN acc ROI Basic\":KNN_acc_ROI_tracker_basic,\n",
    "                          \"KNN acc Accuracy Enhanced\":KNN_acc_accuracy_tracker_enh,\n",
    "                          \"KNN acc ROI Enhanced\":KNN_acc_ROI_tracker_enh\n",
    "\n",
    "                          })\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4639bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv\n",
    "results_df.to_csv(\"../data/Results-Data/model_performance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ceb2ac0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.bar(['f','u'],[0,1])\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.bar(list(feature_difference_df.columns),best_LR_logloss_model.coef_[0])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
